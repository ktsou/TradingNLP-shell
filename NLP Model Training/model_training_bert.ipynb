{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba1ccc6",
   "metadata": {
    "id": "p2B9-HFJBOyq"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6aee855",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7JnZmri5j2_",
    "outputId": "818fb176-5d2f-4af4-c977-85d12e6b936d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.5\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4d84af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXO5FPswBLSH",
    "outputId": "9d331249-1cb7-405b-e589-03d0b7c67436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in c:\\users\\konst\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\konst\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow_hub) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\konst\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\konst\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "#!pip install keras tf-models-official pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b085dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fbf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.official import nlp\n",
    "\n",
    "from official.official.nlp import bert\n",
    "\n",
    "from official.official.nlp.bert import tokenization as tokenization\n",
    "from official.official import modeling as modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e1ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#%load_ext nb_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "plt.style.use(style=\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4bce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4ef09e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHzoXf8sCxaW",
    "outputId": "85830d65-5942-4fc1-c4ce-4ae1830812bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from official import nlp\n",
    "\n",
    "# from official.modeling import tf_utils\n",
    "# from official.nlp import bert\n",
    "# import official.nlp.bert.bert_models\n",
    "# import official.nlp.bert.configs\n",
    "# import official.nlp.bert.run_classifier\n",
    "# import official.nlp.bert.tokenization as tokenization\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('CPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39b2e0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825a0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_LABELLED_DATA_FILEPATH = '..\\Data\\Sentiment Analysis Dataset.csv'\n",
    "txt_data = pd.read_csv(SENTIMENT_LABELLED_DATA_FILEPATH , sep='|', names=['col1'])\n",
    "\n",
    "#split data into columns with ','\n",
    "txt_data = txt_data.col1.str.split(',',  3, expand=True)\n",
    "txt_data.columns = list(txt_data.iloc[0])\n",
    "txt_data = txt_data.drop(0)\n",
    "txt_data.index = np.subtract(txt_data.index, 1)\n",
    "# x = txt_data.groupby('Sentiment')\n",
    "# l=[x.get_group(i)['SentimentText'] for i in x.groups]\n",
    "df = pd.concat([txt_data['SentimentText'], txt_data['Sentiment']], axis = 1)\n",
    "df.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da35c6f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "cYgtLWXODYFJ",
    "outputId": "65aecf27-c816-4d79-b59e-d0c1a8cb0efc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text target\n",
       "0                       is so sad for my APL frie...      0\n",
       "1                     I missed the New Moon trail...      0\n",
       "2                            omg its already 7:30 :O      1\n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...      0\n",
       "4           i think mi bf is cheating on me!!!   ...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaedfe3",
   "metadata": {
    "id": "5x34_8GvDf9C"
   },
   "source": [
    "We have two classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcc5616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8klwmVODcqW",
    "outputId": "74b12285-387a-4556-af33-55e0ce326e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1582f2",
   "metadata": {
    "id": "iyohoWzbDj84"
   },
   "source": [
    "Let's check how equally distributed those classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5eb854",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "bCtMIyUjDh3Z",
    "outputId": "4ce84fd5-97ee-45cd-9940-c11786eb8050"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = df.target.unique()\n",
    "counts = []\n",
    "\n",
    "for i in classes:\n",
    "  count = len(df[df.target==i])\n",
    "  counts.append(count)\n",
    "\n",
    "plt.bar(['negative', 'positive'], counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882ad26",
   "metadata": {
    "id": "HCwKlyvtD2wB"
   },
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0499cc85",
   "metadata": {
    "id": "I2bcU8X_Dz9M"
   },
   "outputs": [],
   "source": [
    "sample_size = int(len(df)*0.03)\n",
    "sampleDf = df.sample(sample_size, random_state=23)\n",
    "x = sampleDf.text.values\n",
    "y = sampleDf.target.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3368a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47335,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4f535",
   "metadata": {
    "id": "R6CgL-y4EI3o"
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18df72e3",
   "metadata": {
    "id": "0mmW4jGVDmCH"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1776bf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0e730a",
   "metadata": {
    "id": "cwQNtv17EdUz"
   },
   "outputs": [],
   "source": [
    "encoder_fname = 'twitter_classes.npy'\n",
    "my_wd = './'\n",
    "np.save(os.path.join(my_wd, encoder_fname) , encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b99a95",
   "metadata": {
    "id": "HEopM33sE_Et"
   },
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# encoder.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac058a",
   "metadata": {
    "id": "Rq5GSy35Gibn"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5049a87a",
   "metadata": {
    "id": "atMa7VWVFQwV"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Konst\\AppData\\Local\\Temp\\tfhub_modules\\3e9209b9f2a53dfa4e6d93250dfceb5e64d73b66\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-dd1193e77a30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",\n\u001b[0m\u001b[0;32m      2\u001b[0m                             trainable=False)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_is_hub_module_v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Expected before TF2.4.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   \"\"\"\n\u001b[1;32m--> 869\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    879\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 881\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m   \"\"\"\n\u001b[1;32m---> 56\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m   debug_info_path = os.path.join(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Konst\\AppData\\Local\\Temp\\tfhub_modules\\3e9209b9f2a53dfa4e6d93250dfceb5e64d73b66\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb3fbe",
   "metadata": {
    "id": "VoD6yod_FRyN"
   },
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93ea7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "d0JoikgjFTmk",
    "outputId": "6fb835af-b863-4d98-eed9-eaecf95de217"
   },
   "outputs": [],
   "source": [
    "do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8c8d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "q1Y7q4QTKuTD",
    "outputId": "5f414f0d-0b4b-404d-bc4b-0714b15223df"
   },
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57f32f",
   "metadata": {
    "id": "-DIT-v6bIFrw"
   },
   "outputs": [],
   "source": [
    "def encode_names(n):\n",
    "   tokens = list(tokenizer.tokenize(n))\n",
    "   tokens.append('[SEP]')  # seperation token. Would bemuch more useful if you had a multiple text input.\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "tweets = tf.ragged.constant([\n",
    "    encode_names(n) for n in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3293cee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jfcVehzDK_--",
    "outputId": "f9b1b310-15ce-4e3b-cda3-18bdb68c8efc"
   },
   "outputs": [],
   "source": [
    "print('Tokenized Tweets shape', tweets.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841984d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "aQ9_HEAiLXUI",
    "outputId": "d405bc1b-d9c5-42e3-f809-d43f30f68576"
   },
   "outputs": [],
   "source": [
    "tokenizedTweet = tokenizer.tokenize(x_train[0])\n",
    "for i in tokenizedTweet:\n",
    "  print(i, tokenizer.convert_tokens_to_ids([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9f2ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "XOenrketMSKq",
    "outputId": "7c802c11-c4eb-4c77-f4b5-e556fe0595a7"
   },
   "outputs": [],
   "source": [
    "cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*tweets.shape[0]\n",
    "input_word_ids = tf.concat([cls, tweets], axis=-1)\n",
    "_ = plt.pcolormesh(input_word_ids[0:10].to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc4707",
   "metadata": {
    "id": "7dKZpLlvQznW"
   },
   "source": [
    "## Mask and input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b6ed2",
   "metadata": {
    "id": "DElTR00ENbYf"
   },
   "outputs": [],
   "source": [
    "input_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d123b72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "PNCmIxTbQ3L-",
    "outputId": "ef0939c3-7cc8-41de-c1b8-033644a9d7ce"
   },
   "outputs": [],
   "source": [
    "input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "plt.pcolormesh(input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf4c23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "4-eSiqx-Q6t7",
    "outputId": "21f4daf8-3eb1-48d5-c66b-29e0284c3379"
   },
   "outputs": [],
   "source": [
    "type_cls = tf.zeros_like(cls)\n",
    "type_tweet = tf.ones_like(tweets)\n",
    "input_type_ids = tf.concat([type_cls, type_tweet], axis=-1).to_tensor()\n",
    "\n",
    "plt.pcolormesh(input_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ef5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "wPy0lCwtRs1f",
    "outputId": "4bc8d438-56ee-4b52-d1cd-39f796925238"
   },
   "outputs": [],
   "source": [
    "input_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1edf0",
   "metadata": {
    "id": "EkRhOGvoSrTi"
   },
   "source": [
    "## Remake into a function for normal use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88896ccf",
   "metadata": {
    "id": "e6gshuXmRwJ8"
   },
   "outputs": [],
   "source": [
    "lens = [len(i) for i in input_word_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006295ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-Yb9EjKDTNhj",
    "outputId": "b1dc3ffa-5020-4283-b436-dcbbaa9dc1ff"
   },
   "outputs": [],
   "source": [
    "max_seq_length = max(lens)\n",
    "print('Max length is:', max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797f571",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1-MsePX3Zq0E",
    "outputId": "41bc825d-7621-4e38-c87b-1e212e06d36f"
   },
   "outputs": [],
   "source": [
    "max_seq_length = int(1.5*max_seq_length)\n",
    "print('Max length is:', max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4936dd8",
   "metadata": {
    "id": "YYTddxJZT4cS"
   },
   "outputs": [],
   "source": [
    "def encode_names(n, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(n))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def bert_encode(string_list, tokenizer, max_seq_length):\n",
    "  num_examples = len(string_list)\n",
    "  \n",
    "  string_tokens = tf.ragged.constant([\n",
    "      encode_names(n, tokenizer) for n in np.array(string_list)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\n",
    "  input_word_ids = tf.concat([cls, string_tokens], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_tokens = tf.ones_like(string_tokens)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_tokens], axis=-1).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids}\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470cb0f",
   "metadata": {
    "id": "8K_R_A3lULSO"
   },
   "source": [
    "And now we preprocess inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02597f",
   "metadata": {
    "id": "3X6EQXxVUi4s"
   },
   "outputs": [],
   "source": [
    "X_train = bert_encode(x_train, tokenizer, max_seq_length)\n",
    "X_test = bert_encode(x_test, tokenizer, max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283601b",
   "metadata": {
    "id": "nJ6PVsxmVbRO"
   },
   "source": [
    "#  MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c423a8b",
   "metadata": {
    "id": "4QVhnrzH9ygq"
   },
   "source": [
    "## Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b3c50",
   "metadata": {
    "id": "TENzkxMeThTv"
   },
   "outputs": [],
   "source": [
    "num_class = len(encoder.classes_)  # Based on available class selection\n",
    "max_seq_length = max_seq_length  # we calculated this a couple cells ago\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])                                  \n",
    "\n",
    "# output = tf.keras.layers.Dense(100, activation='relu')(pooled_output)\n",
    "\n",
    "# output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name='output')(output)\n",
    "\n",
    "output = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "output = tf.keras.layers.Dense(768, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(400, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(200, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(100, activation='relu')(output)\n",
    "output = tf.keras.layers.Dense(num_class, activation='sigmoid', name='output')(output)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs={\n",
    "        'input_word_ids': input_word_ids,\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': segment_ids\n",
    "        },\n",
    "        outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19859bb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "oN0Kh1ruUWPF",
    "outputId": "7f3edf43-f673-42a3-ee16-c9f32823fd5c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aba13",
   "metadata": {
    "id": "bNeskVwpUco0"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 20  # select based on your GPU resources\n",
    "eval_batch_size = batch_size\n",
    "\n",
    "train_data_size = len(dummy_y_train)\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=2e-5,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "# optimizer = nlp.optimization.create_optimizer(\n",
    "#     2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684bf4a",
   "metadata": {
    "id": "dpXu5QfFWAoD"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07594ffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "K0-u2YKQWDAV",
    "outputId": "5989c074-e538-40d7-93eb-90ed8e406d4a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow-gpu test\n",
    "# import tensorflow as tf\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebf823",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "ATMWQDkVWY6n",
    "outputId": "5ca423e7-92c6-45ad-9a46-7fd163633abf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    dummy_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, dummy_y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0929dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = 'model_BERT_non-trainable'\n",
    "my_wd = './'\n",
    "\n",
    "model.save(os.path.join(my_wd, model_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58a534",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "6yY0h7CPXWD_",
    "outputId": "5e3db6ec-7c47-4d11-f771-838a065bf79c"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, dummy_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, dummy_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20859301",
   "metadata": {
    "id": "n1jJDOPzXcEH"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacc2c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "RY7XA4HP9S7H",
    "outputId": "e0fa6cce-c75d-43f3-edcb-dc128f1fc108"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189e2e9",
   "metadata": {},
   "source": [
    "## Tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe2a96",
   "metadata": {
    "id": "9BOIJwPAazvD"
   },
   "outputs": [],
   "source": [
    "tokenizerSaved = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(my_wd, model_fname, 'assets/vocab.txt'),\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d40e9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "iE3HggMgbkVO",
    "outputId": "6116d77a-0529-4ea0-a247-c904e4a994dd"
   },
   "outputs": [],
   "source": [
    "tokenizedTweet = tokenizerSaved.tokenize(x_train[0])\n",
    "for i in tokenizedTweet:\n",
    "  print(i, tokenizerSaved.convert_tokens_to_ids([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60838123",
   "metadata": {
    "id": "WMhBzgkd5zAM"
   },
   "source": [
    "## Second training itteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d822e9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "XaNCm8S6Xd2G",
    "outputId": "d00ad1fb-2514-4dca-fc76-99c0acf05cf0"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5e733",
   "metadata": {
    "id": "UotwRyBE6NP0"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc3ff5",
   "metadata": {
    "id": "mXXGcaZM54hg"
   },
   "outputs": [],
   "source": [
    "sample_size = int(len(df)*0.05)\n",
    "sampleDf = df.sample(sample_size, random_state=42)  # notice the random state changes\n",
    "x = sampleDf.text.values\n",
    "y = sampleDf.target.values\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.20, random_state=42)  # notice the random state changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a19af1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "wC2tIF7-67F4",
    "outputId": "d4a94d05-920d-4ba2-d4ca-a2d59d346fc2"
   },
   "outputs": [],
   "source": [
    "classes = sampleDf.target.unique()\n",
    "print(classes)\n",
    "counts = []\n",
    "\n",
    "for i in classes:\n",
    "  count = len(sampleDf[sampleDf.target==i])\n",
    "  counts.append(count)\n",
    "\n",
    "plt.bar(['negative', 'positive'], counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d93fb0",
   "metadata": {
    "id": "vAKNqpPh7c2M"
   },
   "source": [
    "#### Label Encoding\n",
    "Now we need to encode labels again. Good thing we have our label encoder saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed5e4a",
   "metadata": {
    "id": "teAtzXqt7ki-"
   },
   "outputs": [],
   "source": [
    "encoder_fname = 'twitter_classes.npy'\n",
    "my_wd = '/content/drive/My Drive/YouTube/botters_2020-10/twitter_sentiment_course/'\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)\n",
    "\n",
    "encoded_Y_test2 = encoder.transform(y_test2)\n",
    "encoded_Y_train2 = encoder.transform(y_train2)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test2 = np_utils.to_categorical(encoded_Y_test2)\n",
    "dummy_y_train2 = np_utils.to_categorical(encoded_Y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6e514",
   "metadata": {
    "id": "5c_9kIrI8cDz"
   },
   "source": [
    "#### Input preprocessing\n",
    "As we did before we need to tokenize our inputs (tweets) as `input_word_ids` and then add `input_mask` and `input_type`. As we saved our model, we can use it to build our tokenizer as it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3d547",
   "metadata": {
    "id": "lRDJu1jJ8mlF"
   },
   "outputs": [],
   "source": [
    "model_fname = 'twitter_BERT'\n",
    "my_wd = '/content/drive/My Drive/YouTube/botters_2020-10/twitter_sentiment_course/'\n",
    "\n",
    "tokenizerSaved = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(my_wd, model_fname, 'assets/vocab.txt'),\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233ebc8",
   "metadata": {
    "id": "wB9ImmkYbxJo"
   },
   "outputs": [],
   "source": [
    "def encode_names(n, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(n))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def bert_encode(string_list, tokenizer, max_seq_length):\n",
    "  num_examples = len(string_list)\n",
    "  \n",
    "  string_tokens = tf.ragged.constant([\n",
    "      encode_names(n, tokenizer) for n in np.array(string_list)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\n",
    "  input_word_ids = tf.concat([cls, string_tokens], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_tokens = tf.ones_like(string_tokens)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_tokens], axis=-1).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids}\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2d7a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ACSBixa4CUg5",
    "outputId": "53ee8b2c-7a0d-415b-c02d-60837bed802b"
   },
   "outputs": [],
   "source": [
    "print('Max sequence length is:', max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95763ddb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "YoKZh0u0CcVT",
    "outputId": "dee019bb-0155-4b1c-a357-f8c16b3807c7"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c39c5",
   "metadata": {
    "id": "uiE8pkuqB6k_"
   },
   "outputs": [],
   "source": [
    "X_train2 = bert_encode(x_train2, tokenizerSaved, max_seq_length)\n",
    "X_test2 = bert_encode(x_test2, tokenizerSaved, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1543928",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1FG6bmxm6hQo",
    "outputId": "34ab3231-b325-4260-ebdd-095ba8242d02"
   },
   "outputs": [],
   "source": [
    "x_train2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceba96d",
   "metadata": {
    "id": "dXHn00cwDWac"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b210cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "oIcOCiswDN9P",
    "outputId": "0c66274d-9b9e-4eee-ea6f-64e6c289b943"
   },
   "outputs": [],
   "source": [
    "model_fname = 'twitter_BERT'\n",
    "my_wd = '/content/drive/My Drive/YouTube/botters_2020-10/twitter_sentiment_course/'\n",
    "\n",
    "new_model = tf.keras.models.load_model(os.path.join(my_wd, model_fname))\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbaba6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "yapkpJpXIFpw",
    "outputId": "bb17ca99-b780-4321-bf20-7db4f6794e3c"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(new_model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16f8ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "1n4i6qwPDtlM",
    "outputId": "6f5d9906-fe7c-4168-ab40-7889e422b074"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = new_model.evaluate(X_test, dummy_y_test, verbose=False)  # OLD\n",
    "print(\"Old testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = new_model.evaluate(X_test2, dummy_y_test2, verbose=False)  # NEW\n",
    "print(\"New testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1c78c",
   "metadata": {
    "id": "TfgAOC5KERoI"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 16  # select based on your GPU resources\n",
    "eval_batch_size = batch_size\n",
    "\n",
    "train_data_size = len(dummy_y_train2)\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836377ce",
   "metadata": {
    "id": "mIKL2_TXHKNP"
   },
   "outputs": [],
   "source": [
    "optimizer = nlp.optimization.create_optimizer(\n",
    "    2e-6, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c60e45",
   "metadata": {
    "id": "up0osQrxHntP"
   },
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c3893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "H4_BM84kH03L",
    "outputId": "87741068-0115-42c5-f20f-4b3adbbde8de"
   },
   "outputs": [],
   "source": [
    "history2 = new_model.fit(X_train2,  # using new training set\n",
    "                         dummy_y_train2,  # using new training set\n",
    "                         epochs=epochs,\n",
    "                         batch_size=batch_size,\n",
    "                         validation_data=(X_test, dummy_y_test),  # using old test dataset\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815ff89",
   "metadata": {
    "id": "cHkRaP7Cpf_V"
   },
   "outputs": [],
   "source": [
    "for i in history2.history:\n",
    "  for ele in history2.history[i]:\n",
    "    history.history[i].append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602057a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Ug8_LyTbqxcS",
    "outputId": "331c31f4-85a9-467a-beaa-03b4c3c962ef"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9aed50",
   "metadata": {
    "id": "F5y81Wvk1Cav"
   },
   "source": [
    "# Is BERT worth it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a503d",
   "metadata": {
    "id": "aQIJMSxWRNOX"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836244c",
   "metadata": {
    "id": "CvXzVKLNS3EZ"
   },
   "source": [
    "We need to check in with our label encoder to get our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb656e",
   "metadata": {
    "id": "Q48W5efMSdtI"
   },
   "outputs": [],
   "source": [
    "encoder_fname = 'twitter_classes.npy'\n",
    "my_wd = '/content/drive/My Drive/YouTube/botters_2020-10/twitter_sentiment_course/'\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a3a2a",
   "metadata": {
    "id": "XgjPsHVcTX9V"
   },
   "source": [
    "This is how our classes are encoded for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5236d9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZT2DvZ2oTCBJ",
    "outputId": "452e542a-04ea-4665-d26c-72fb71c00e05"
   },
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3504d",
   "metadata": {
    "id": "-aVOr8MlSxa6"
   },
   "source": [
    "Input preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6de949",
   "metadata": {
    "id": "SiruBLfcrCUo"
   },
   "outputs": [],
   "source": [
    "tweet = ['SLEEPY JOE BIDEN IS PROPOSING THE BIGGEST TAX HIKE IN OUR COUNTRIES HISTORY! CAN ANYBODY REALLY VOTE FOR THIS?']\n",
    "inputs = bert_encode(string_list=list(tweet), \n",
    "                     tokenizer=tokenizerSaved, \n",
    "                     max_seq_length=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede7032",
   "metadata": {
    "id": "Zkoy3SgCTdgc"
   },
   "source": [
    "Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469c014",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQWW5CCtTDji",
    "outputId": "1a503d85-35e8-44cd-ed11-6236e96e4692"
   },
   "outputs": [],
   "source": [
    "prediction = new_model.predict(inputs)\n",
    "print(prediction)\n",
    "print('Tweet is', 'positive' if encoder.classes_[np.argmax(prediction)]==4 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ab586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq-DshwxTt4n",
    "outputId": "193c8479-8102-4f65-e3de-d9b1fc9322bd"
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
