{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bb1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#%load_ext nb_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "plt.style.use(style=\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e649b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_LABELLED_DATA_FILEPATH = '..\\Data\\Sentiment Analysis Dataset.csv'\n",
    "DATA_PREPROCESSING_FILEPATH = '../Data Preprocessed'\n",
    "\n",
    "TOKENIZER_OUTPUT_FILEPATH = 'tokenizer_100K.pickle'\n",
    "MODEL_OUTPUT_FILEPATH = 'model_100K_glove'\n",
    "# MODEL_OUTPUT_FILEPATH = 'model_100K_glove'\n",
    "MODEL_OUTPUT_FILEPATH = 'model_100K_glove_91'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff7143",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9519badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = pd.read_csv(SENTIMENT_LABELLED_DATA_FILEPATH , sep='|', names=['col1'])\n",
    "\n",
    "#split data into columns with ','\n",
    "txt_data = txt_data.col1.str.split(',',  3, expand=True)\n",
    "txt_data.columns = list(txt_data.iloc[0])\n",
    "txt_data = txt_data.drop(0)\n",
    "txt_data.index = np.subtract(txt_data.index, 1)\n",
    "# x = txt_data.groupby('Sentiment')\n",
    "# l=[x.get_group(i)['SentimentText'] for i in x.groups]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856b69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([txt_data['SentimentText'], txt_data['Sentiment']], axis = 1)\n",
    "dataset.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "def5b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1577838 entries, 0 to 1577837\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1577838 non-null  object\n",
      " 1   target  1577838 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 36.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text target\n",
       "0                       is so sad for my APL frie...      0\n",
       "1                     I missed the New Moon trail...      0\n",
       "2                            omg its already 7:30 :O      1\n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...      0\n",
       "4           i think mi bf is cheating on me!!!   ...      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(dataset.info(verbose=True))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d19c632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228040</th>\n",
       "      <td>Sometimes things do work in my favor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600218</th>\n",
       "      <td>and i fail epicly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204630</th>\n",
       "      <td>This time I won't get back on twitter until th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178857</th>\n",
       "      <td>\"@gruuvebot It's the damn back thing, otherwis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209766</th>\n",
       "      <td>@jamescollier Friggan jealous! I need some mor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842311</th>\n",
       "      <td>@Icepartyscott thats cool suzi is doin the ice...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848506</th>\n",
       "      <td>@IndywoodFILMS fly me to the UK and I will be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801538</th>\n",
       "      <td>\"has decided not to buy boxing - only my first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803669</th>\n",
       "      <td>@galindafied Thanks!  I'm a little rusty (have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119972</th>\n",
       "      <td>rt @FightRecession WATCH THE FULL FIGHT OF PAC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577838 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text target\n",
       "1228040              Sometimes things do work in my favor       1\n",
       "600218                                  and i fail epicly       0\n",
       "1204630  This time I won't get back on twitter until th...      1\n",
       "178857   \"@gruuvebot It's the damn back thing, otherwis...      1\n",
       "209766   @jamescollier Friggan jealous! I need some mor...      0\n",
       "...                                                    ...    ...\n",
       "842311   @Icepartyscott thats cool suzi is doin the ice...      0\n",
       "848506   @IndywoodFILMS fly me to the UK and I will be ...      1\n",
       "801538   \"has decided not to buy boxing - only my first...      0\n",
       "803669   @galindafied Thanks!  I'm a little rusty (have...      1\n",
       "1119972  rt @FightRecession WATCH THE FULL FIGHT OF PAC...      1\n",
       "\n",
       "[1577838 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suffle\n",
    "dataset = dataset.sample(frac = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd0bb3e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append(DATA_PREPROCESSING_FILEPATH)\n",
    "from data_preprocess import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f2e67c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c926c221defc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNLP_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\PythonNotebooks\\TradingNLP\\NLP Model Training\\../Data Preprocessed\\data_preprocess.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(self, field)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;31m#self.df[field] = self.df[field].map(lambda x: lowercase_remove_stopwords(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   3907\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3908\u001b[0m         \"\"\"\n\u001b[1;32m-> 3909\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3910\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   3911\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\PythonNotebooks\\TradingNLP\\NLP Model Training\\../Data Preprocessed\\data_preprocess.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;31m#self.df[field] = self.df[field].map(lambda x: lowercase_remove_stopwords(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\PythonNotebooks\\TradingNLP\\NLP Model Training\\../Data Preprocessed\\data_preprocess.py\u001b[0m in \u001b[0;36mremove_stopwords\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\PythonNotebooks\\TradingNLP\\NLP Model Training\\../Data Preprocessed\\data_preprocess.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = NLP_preprocess(dataset)\n",
    "text.preprocess_data()\n",
    "\n",
    "text.set_tokenizer()\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(TOKENIZER_OUTPUT_FILEPATH, 'wb') as handle:\n",
    "    pickle.dump(text.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04f0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   506    137     12 ...      0      0      0]\n",
      " [   463  27881      0 ...      0      0      0]\n",
      " [    15    109      5 ...      0      0      0]\n",
      " ...\n",
      " [   115     65      4 ...      0      0      0]\n",
      " [107090    541    210 ...      0      0      0]\n",
      " [107091  10846   5105 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[:100000]\n",
    "#train_dataset = dataset[:1000000]\n",
    "train_labels = train_dataset.target.astype(float)\n",
    "train_padded = text.tokenize_and_pad(train_dataset, train = True)\n",
    "print(train_padded)\n",
    "# saving\n",
    "with open(TOKENIZER_OUTPUT_FILEPATH, 'wb') as handle:\n",
    "    pickle.dump(text.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef1f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.set_embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6eb9335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1aaa066e42ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(text.embedding_matrix).info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7442a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  506   137    12 ...     0     0     0]\n",
      " [  463 27881     0 ...     0     0     0]\n",
      " [   15   109     5 ...     0     0     0]\n",
      " ...\n",
      " [21242    49  7475 ...     0     0     0]\n",
      " [43679    91  1129 ...     0     0     0]\n",
      " [  968    27  3499 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[:20000]\n",
    "test_labels = test_dataset.target.astype(float)\n",
    "test_padded = text.tokenize_and_pad(test_dataset, train = False)\n",
    "print(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b75b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# trainable = False\n",
    "#bidirectional\n",
    "\n",
    "#Glove\n",
    "model.add(\n",
    "    Embedding(\n",
    "        text.num_words,\n",
    "        100,\n",
    "        embeddings_initializer = Constant(text.embedding_matrix),\n",
    "        input_length = text.max_length,\n",
    "        trainable = False,\n",
    "    )\n",
    ")\n",
    "\n",
    "#basic\n",
    "# for i in range(0,200):\n",
    "# #model.add(Embedding(text.num_words, 8, input_length=text.max_length))\n",
    "#     model.add(Dense(1000, activation='relu'))\n",
    "model.add(LSTM(100, dropout=0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cb475f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           10709300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,789,801\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 10,709,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9268ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3885 - accuracy: 0.8206 - val_loss: 0.3579 - val_accuracy: 0.8372\n",
      "Epoch 2/40\n",
      "3125/3125 [==============================] - 14s 5ms/step - loss: 0.3848 - accuracy: 0.8239 - val_loss: 0.3458 - val_accuracy: 0.8438\n",
      "Epoch 3/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3799 - accuracy: 0.8267 - val_loss: 0.3479 - val_accuracy: 0.8446\n",
      "Epoch 4/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3757 - accuracy: 0.8283 - val_loss: 0.3435 - val_accuracy: 0.8477\n",
      "Epoch 5/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3708 - accuracy: 0.8316 - val_loss: 0.3332 - val_accuracy: 0.8547\n",
      "Epoch 6/40\n",
      "3125/3125 [==============================] - 14s 5ms/step - loss: 0.3667 - accuracy: 0.8330 - val_loss: 0.3265 - val_accuracy: 0.8585\n",
      "Epoch 7/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3635 - accuracy: 0.8344 - val_loss: 0.3227 - val_accuracy: 0.8576\n",
      "Epoch 8/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3591 - accuracy: 0.8378 - val_loss: 0.3164 - val_accuracy: 0.8615\n",
      "Epoch 9/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3547 - accuracy: 0.8387 - val_loss: 0.3205 - val_accuracy: 0.8603\n",
      "Epoch 10/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3507 - accuracy: 0.8400 - val_loss: 0.3050 - val_accuracy: 0.8640\n",
      "Epoch 11/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3469 - accuracy: 0.8431 - val_loss: 0.3048 - val_accuracy: 0.8683\n",
      "Epoch 12/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3428 - accuracy: 0.8454 - val_loss: 0.2991 - val_accuracy: 0.8711\n",
      "Epoch 13/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3416 - accuracy: 0.8463 - val_loss: 0.2929 - val_accuracy: 0.8745\n",
      "Epoch 14/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3366 - accuracy: 0.8483 - val_loss: 0.2901 - val_accuracy: 0.8765\n",
      "Epoch 15/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3322 - accuracy: 0.8511 - val_loss: 0.2938 - val_accuracy: 0.8719\n",
      "Epoch 16/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3293 - accuracy: 0.8522 - val_loss: 0.2840 - val_accuracy: 0.8793\n",
      "Epoch 17/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3259 - accuracy: 0.8537 - val_loss: 0.2776 - val_accuracy: 0.8851\n",
      "Epoch 18/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3236 - accuracy: 0.8546 - val_loss: 0.2747 - val_accuracy: 0.8830\n",
      "Epoch 19/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3206 - accuracy: 0.8566 - val_loss: 0.2695 - val_accuracy: 0.8840\n",
      "Epoch 20/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3186 - accuracy: 0.8576 - val_loss: 0.2676 - val_accuracy: 0.8866\n",
      "Epoch 21/40\n",
      "3125/3125 [==============================] - 14s 5ms/step - loss: 0.3166 - accuracy: 0.8583 - val_loss: 0.2687 - val_accuracy: 0.8836\n",
      "Epoch 22/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3131 - accuracy: 0.8603 - val_loss: 0.2506 - val_accuracy: 0.8913\n",
      "Epoch 23/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.3092 - accuracy: 0.8621 - val_loss: 0.2565 - val_accuracy: 0.8906\n",
      "Epoch 24/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.3055 - accuracy: 0.8643 - val_loss: 0.2538 - val_accuracy: 0.8903\n",
      "Epoch 25/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.3038 - accuracy: 0.8643 - val_loss: 0.2521 - val_accuracy: 0.8959\n",
      "Epoch 26/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3012 - accuracy: 0.8653 - val_loss: 0.2414 - val_accuracy: 0.8992\n",
      "Epoch 27/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3006 - accuracy: 0.8664 - val_loss: 0.2384 - val_accuracy: 0.8983\n",
      "Epoch 28/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2963 - accuracy: 0.8691 - val_loss: 0.2335 - val_accuracy: 0.9021\n",
      "Epoch 29/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2924 - accuracy: 0.8697 - val_loss: 0.2343 - val_accuracy: 0.9001\n",
      "Epoch 30/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2909 - accuracy: 0.8724 - val_loss: 0.2301 - val_accuracy: 0.9021\n",
      "Epoch 31/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2935 - accuracy: 0.8685 - val_loss: 0.2440 - val_accuracy: 0.8938\n",
      "Epoch 32/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2880 - accuracy: 0.8725 - val_loss: 0.2312 - val_accuracy: 0.9040\n",
      "Epoch 33/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2862 - accuracy: 0.8725 - val_loss: 0.2349 - val_accuracy: 0.9017\n",
      "Epoch 34/40\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 0.2839 - accuracy: 0.8742 - val_loss: 0.2221 - val_accuracy: 0.9056\n",
      "Epoch 35/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2815 - accuracy: 0.8754 - val_loss: 0.2240 - val_accuracy: 0.9069\n",
      "Epoch 36/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2809 - accuracy: 0.8763 - val_loss: 0.2142 - val_accuracy: 0.9105\n",
      "Epoch 37/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2769 - accuracy: 0.8777 - val_loss: 0.2212 - val_accuracy: 0.9115\n",
      "Epoch 38/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2775 - accuracy: 0.8767 - val_loss: 0.2076 - val_accuracy: 0.9142\n",
      "Epoch 39/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2735 - accuracy: 0.8794 - val_loss: 0.2049 - val_accuracy: 0.9123\n",
      "Epoch 40/40\n",
      "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2742 - accuracy: 0.8801 - val_loss: 0.2087 - val_accuracy: 0.9123\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_labels, epochs=40, validation_data=(test_padded, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7926c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_100K_glove_91\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_100K_glove_91\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_OUTPUT_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5a3082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  ohmymandy lucky met\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8493518]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "#test_neg = random.choice(neg.values)\n",
    "i = random.choice(test_dataset.index)\n",
    "if test_dataset.loc[i]['target'] == '0':\n",
    "    print('negative: ', test_dataset.loc[i]['text'])\n",
    "else:\n",
    "    print('positive: ', test_dataset.loc[i]['text'])\n",
    "test_sequences = text.tokenizer.texts_to_sequences([test_dataset.loc[i]['text']])\n",
    "test_padded2 = pad_sequences(\n",
    "    test_sequences, maxlen=text.max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "model.predict(test_padded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dea30a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# model = keras.models.load_model('C:/Users/Konst/Desktop/PythonNotebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c125241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
