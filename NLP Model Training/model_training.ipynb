{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bb1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#%load_ext nb_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "plt.style.use(style=\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff7143",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9519badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = pd.read_csv('..\\Data\\Sentiment Analysis Dataset.csv' , sep='|', names=['col1'])\n",
    "\n",
    "#split data into columns with ','\n",
    "txt_data = txt_data.col1.str.split(',',  3, expand=True)\n",
    "txt_data.columns = list(txt_data.iloc[0])\n",
    "txt_data = txt_data.drop(0)\n",
    "txt_data.index = np.subtract(txt_data.index, 1)\n",
    "# x = txt_data.groupby('Sentiment')\n",
    "# l=[x.get_group(i)['SentimentText'] for i in x.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856b69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([txt_data['SentimentText'], txt_data['Sentiment']], axis = 1)\n",
    "dataset.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def5b960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577833</th>\n",
       "      <td>Zzzzzz.... Finally! Night tweeters!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577834</th>\n",
       "      <td>\"Zzzzzzz, sleep well people \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577835</th>\n",
       "      <td>ZzzZzZzzzZ... wait no I have homework.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577836</th>\n",
       "      <td>\"ZzZzzzZZZZzzz meh, what am I doing up again? \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577837</th>\n",
       "      <td>\"Zzzzzzzzzzzzzzzzzzz, I wish \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577838 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text target\n",
       "0                             is so sad for my APL frie...      0\n",
       "1                           I missed the New Moon trail...      0\n",
       "2                                  omg its already 7:30 :O      1\n",
       "3                  .. Omgaga. Im sooo  im gunna CRy. I'...      0\n",
       "4                 i think mi bf is cheating on me!!!   ...      0\n",
       "...                                                    ...    ...\n",
       "1577833               Zzzzzz.... Finally! Night tweeters!       1\n",
       "1577834                      \"Zzzzzzz, sleep well people \"      1\n",
       "1577835            ZzzZzZzzzZ... wait no I have homework.       0\n",
       "1577836    \"ZzZzzzZZZZzzz meh, what am I doing up again? \"      0\n",
       "1577837                     \"Zzzzzzzzzzzzzzzzzzz, I wish \"      0\n",
       "\n",
       "[1577838 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd0bb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('../Data Preprocesed')\n",
    "from data_preprocess import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f2e67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = NLP_preprocess(dataset)\n",
    "text.preprocess_data()\n",
    "\n",
    "text.set_tokenizer()\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer_1M.pickle', 'wb') as handle:\n",
    "    pickle.dump(text.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04f0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    56 196012    170 ...      0      0      0]\n",
      " [   155     34    796 ...      0      0      0]\n",
      " [   211    105   3687 ...      0      0      0]\n",
      " ...\n",
      " [   174    651    265 ...      0      0      0]\n",
      " [   174     36   5425 ...      0      0      0]\n",
      " [   174   5067      7 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[:1000000]\n",
    "train_labels = train_dataset.target.astype(float)\n",
    "train_padded = text.tokenize_and_pad(train_dataset, train = True)\n",
    "print(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7442a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    56 196012    170 ...      0      0      0]\n",
      " [   155     34    796 ...      0      0      0]\n",
      " [   211    105   3687 ...      0      0      0]\n",
      " ...\n",
      " [   174    651    265 ...      0      0      0]\n",
      " [   174     36   5425 ...      0      0      0]\n",
      " [   174   5067      7 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[:1000000]\n",
    "test_labels = test_dataset.target.astype(float)\n",
    "test_padded = text.tokenize_and_pad(test_dataset, train = False)\n",
    "print(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b75b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(text.num_words, 8, input_length=text.max_length))\n",
    "model.add(LSTM(16, dropout=0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb475f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 8)             6266224   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                1600      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,267,841\n",
      "Trainable params: 6,267,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9268ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_labels, epochs=20, validation_data=(test_padded, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5a3082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:  niccisnail ill definitely write look forward article re5 write fun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9780675]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "#test_neg = random.choice(neg.values)\n",
    "i = random.choice(test_dataset.index)\n",
    "if test_dataset.loc[i]['target'] == '0':\n",
    "    print('negative: ', test_dataset.loc[i]['text'])\n",
    "else:\n",
    "    print('positive: ', test_dataset.loc[i]['text'])\n",
    "test_sequences = text.tokenizer.texts_to_sequences([test_dataset.loc[i]['text']])\n",
    "test_padded2 = pad_sequences(\n",
    "    test_sequences, maxlen=text.max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "model.predict(test_padded2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
